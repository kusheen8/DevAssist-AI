# ğŸš€ DevAssist AI â€” Developer Documentation Assistant

ğŸ”— **Live Demo:** https://devassist-ai.streamlit.app/

DevAssist AI is a **Retrieval-Augmented Generation (RAG)** based developer documentation assistant that allows users to upload technical PDFs (PRDs, specs, API docs, assignments) and ask grounded questions.
The system retrieves relevant content from the uploaded document and generates accurate answers using an LLM â€” while preventing hallucinations through strict prompt guardrails.

---

## âœ¨ Features

* ğŸ“‚ Upload developer documentation PDFs
* ğŸ” Semantic search using embeddings + vector database
* ğŸ¤– Context-aware AI answers powered by Llama 3.1 (Groq)
* ğŸ§  Guardrails to avoid hallucinations
* ğŸ’¬ Chat-style interface with history
* ğŸ“š Developer Mode to view source pages
* âš¡ Fast deployment with Streamlit Cloud

---

## ğŸ§  Architecture Overview

DevAssist AI follows a **RAG (Retrieval Augmented Generation)** pipeline:

```
Upload PDF
   â†“
Text Extraction (PyPDFLoader)
   â†“
Chunking (RecursiveCharacterTextSplitter)
   â†“
Embeddings (MiniLM)
   â†“
Chroma Vector Database
   â†“
Retriever
   â†“
Groq LLM (Llama 3.1)
   â†“
Grounded Answer
```

The model only answers from retrieved document context, ensuring reliable and controlled responses.

---

## ğŸ› ï¸ Tech Stack

### Frontend / Interface

* Streamlit

### Backend / AI Pipeline

* LangChain
* Groq (Llama-3.1-8B-Instant)
* HuggingFace Embeddings (all-MiniLM-L6-v2)

### Vector Database

* ChromaDB

### Document Processing

* PyPDFLoader
* RecursiveCharacterTextSplitter

---

## ğŸ” Guardrails & Safety

* Answers are restricted to uploaded document context
* Non-developer or unrelated queries are blocked
* Temperature set to `0` for deterministic responses
* Custom prompt template prevents hallucinated outputs

---

## ğŸ“¦ Installation (Local Setup)

Clone the repository:

```bash
git clone https://github.com/your-username/devassist-ai.git
cd devassist-ai
```

Create virtual environment:

```bash
python -m venv venv
source venv/bin/activate   # macOS/Linux
venv\Scripts\activate      # Windows
```

Install dependencies:

```bash
pip install -r requirements.txt
```

Add your API key in `.streamlit/secrets.toml`:

```toml
GROQ_API_KEY = "your_api_key_here"
```

Run the app:

```bash
streamlit run app.py
```

---

## ğŸš€ Deployment

The project is deployed using:

* **Streamlit Cloud** for hosting
* Groq API for LLM inference
* Local persistent ChromaDB for embeddings storage

ğŸ‘‰ Live App: https://devassist-ai.streamlit.app/

---

## ğŸ¯ Use Cases & Example Questions

DevAssist AI helps developers quickly understand technical documentation.
Some example questions you can ask after uploading a PDF:

* â€œWhat is the project overview?â€
* â€œExplain the frontend architecture.â€
* â€œWhat backend technologies are used?â€
* â€œDescribe the system workflow.â€
* â€œWhat APIs are implemented?â€
* â€œList the main features mentioned in the document.â€
* â€œExplain the deployment strategy.â€
* â€œWhat database is used?â€
* â€œSummarize the assignment requirements.â€

---

## ğŸ‘©â€ğŸ’» Author

**Kusheen Dhar**
CS Engineering Student | Full Stack & AI Developer

---

## â­ Acknowledgements

* LangChain
* HuggingFace
* Groq
* Streamlit
* ChromaDB

---

> âš™ï¸ Built as a placement-ready AI project demonstrating RAG architecture, LLM integration, and full-stack deployment.
